{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe97b8a7-558f-4a33-8af7-5be824b774dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import transform as shp_transform\n",
    "from pyproj import Transformer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6261de32-6601-481d-8a92-1eedfec50200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUTS (as you uploaded)\n",
    "PATH_HDB_CSV = \"data/hdb_data_2023.csv.xz\"\n",
    "PATH_ZIP_MRT = \"data/MRT Station_06 Jun 2024.zip\"\n",
    "PATH_ZIP_BUS = \"data/BusStopLocation_Aug2025.zip\"\n",
    "PATH_ZIP_PA  = \"data/master-plan-2019-planningarea.zip\"\n",
    "PATH_ZIP_SZ  = \"data/master-plan-2019-subzone_landuse_area.zip\"\n",
    "\n",
    "# OUTPUT DIRECTORY (created if missing)\n",
    "OUT_DIR = Path(\"processed\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# OUTPUT FILES (GeoJSON recommended for portability)\n",
    "OUT_HDB = OUT_DIR / \"hdb_2023_points_3414.geojson\"\n",
    "OUT_MRT = OUT_DIR / \"mrt_2024_points_3414.geojson\"\n",
    "OUT_BUS = OUT_DIR / \"bus_2025_points_3414.geojson\"\n",
    "OUT_PA  = OUT_DIR / \"mp19_planning_areas_3414.geojson\"\n",
    "OUT_SZ  = OUT_DIR / \"mp19_subzones_3414.geojson\"\n",
    "\n",
    "# CRS TARGET\n",
    "TARGET_EPSG = 3414\n",
    "TARGET_CRS = f\"EPSG:{TARGET_EPSG}\"\n",
    "\n",
    "# TEMP extraction\n",
    "TMP_DIR = Path(\"tmp_extract\"); TMP_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "526d8782-d2ba-4eed-9be7-7755c664ba1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_to_dir(zip_path: str | Path, base_dir: Path = TMP_DIR) -> Path:\n",
    "    \"\"\"Extract a .zip to a temp folder and return the folder path.\"\"\"\n",
    "    zip_path = Path(zip_path)\n",
    "    out_dir = base_dir / zip_path.stem\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zf:\n",
    "        zf.extractall(out_dir)\n",
    "    return out_dir\n",
    "\n",
    "def first_shp(dir_path: Path) -> Path | None:\n",
    "    \"\"\"Find the first .shp in a directory tree.\"\"\"\n",
    "    shps = list(Path(dir_path).rglob(\"*.shp\"))\n",
    "    return shps[0] if shps else None\n",
    "\n",
    "def to_2d_geometry(geom):\n",
    "    \"\"\"Drop Z dimension from any Shapely geometry. Works for points, lines, polygons.\"\"\"\n",
    "    if geom is None:\n",
    "        return None\n",
    "    try:\n",
    "        return shp_transform(lambda x, y, z=None: (x, y), geom)\n",
    "    except Exception:\n",
    "        # Fallback for simple Point-like\n",
    "        if hasattr(geom, \"x\") and hasattr(geom, \"y\"):\n",
    "            return Point(geom.x, geom.y)\n",
    "        return geom\n",
    "\n",
    "def reproject_gdf(gdf: gpd.GeoDataFrame, target_crs: str = TARGET_CRS) -> gpd.GeoDataFrame:\n",
    "    \"\"\"Reproject GeoDataFrame to target_crs; if crs missing, you may set gdf.set_crs(...) first.\"\"\"\n",
    "    if gdf.crs is None:\n",
    "        raise ValueError(\"Input layer has no CRS. Set the source CRS before calling reproject.\")\n",
    "    if str(gdf.crs).lower() != target_crs.lower():\n",
    "        gdf = gdf.to_crs(target_crs)\n",
    "    return gdf\n",
    "\n",
    "def robust_reproject_write_polygons_with_fiona(zip_path: str | Path, out_geojson: str | Path):\n",
    "    \"\"\"\n",
    "    Robustly read (with Fiona), reproject (pyproj), convert Polygon->MultiPolygon if needed,\n",
    "    and write to GeoJSON. This avoids common Shapely multipart array interface issues.\n",
    "    \"\"\"\n",
    "    shp_dir = unzip_to_dir(zip_path)\n",
    "    shp_path = first_shp(shp_dir)\n",
    "    if shp_path is None:\n",
    "        raise FileNotFoundError(f\"No .shp found in {zip_path}\")\n",
    "\n",
    "    with fiona.open(shp_path) as src:\n",
    "        # Build coordinate transformer using source CRS -> target EPSG\n",
    "        src_crs = src.crs_wkt or src.crs\n",
    "        transformer = Transformer.from_crs(src_crs, TARGET_CRS, always_xy=True)\n",
    "\n",
    "        # Destination schema: force MultiPolygon (safe superset)\n",
    "        schema = {\n",
    "            \"geometry\": \"MultiPolygon\",\n",
    "            \"properties\": {k: v for k, v in src.schema[\"properties\"].items()},\n",
    "        }\n",
    "\n",
    "        # Write GeoJSON output\n",
    "        with fiona.open(out_geojson, mode=\"w\", driver=\"GeoJSON\", crs=TARGET_CRS, schema=schema) as dst:\n",
    "            for feat in src:\n",
    "                geom = feat[\"geometry\"]\n",
    "                if geom is None:\n",
    "                    continue\n",
    "\n",
    "                # Normalize Polygon to MultiPolygon to match schema\n",
    "                if geom[\"type\"] == \"Polygon\":\n",
    "                    geom = {\"type\": \"MultiPolygon\", \"coordinates\": [geom[\"coordinates\"]]}\n",
    "                elif geom[\"type\"] != \"MultiPolygon\":\n",
    "                    # Attempt to coerce any other type if present (rare)\n",
    "                    continue\n",
    "\n",
    "                # Transform coordinates & drop Z\n",
    "                tgeom = transform_geom_xy(geom, transformer)\n",
    "                dst.write({\"geometry\": tgeom, \"properties\": feat[\"properties\"]})\n",
    "\n",
    "def transform_geom_xy(geom, transformer: Transformer):\n",
    "    \"\"\"Transform all coordinates in a (Multi)Polygon dict to target CRS and drop Z.\"\"\"\n",
    "    gtype = geom[\"type\"]\n",
    "    coords = geom[\"coordinates\"]\n",
    "\n",
    "    def tx_xy(xy):\n",
    "        # xy may include Z; only use x,y\n",
    "        x, y = xy[0], xy[1]\n",
    "        X, Y = transformer.transform(x, y)\n",
    "        return (X, Y)\n",
    "\n",
    "    if gtype == \"MultiPolygon\":\n",
    "        return {\n",
    "            \"type\": \"MultiPolygon\",\n",
    "            \"coordinates\": [\n",
    "                [[tx_xy(c) for c in ring] for ring in poly]\n",
    "                for poly in coords\n",
    "            ],\n",
    "        }\n",
    "    elif gtype == \"Polygon\":  # kept for completeness; we normalize to MultiPolygon above\n",
    "        return {\n",
    "            \"type\": \"Polygon\",\n",
    "            \"coordinates\": [[tx_xy(c) for c in ring] for ring in coords],\n",
    "        }\n",
    "    else:\n",
    "        return geom  # should not occur here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bd52089-bbe6-478a-845c-75ffcf5fe30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ HDB saved: processed\\hdb_2023_points_3414.geojson  |  rows=25760\n"
     ]
    }
   ],
   "source": [
    "# Load HDB CSV and build point geometry from X/Y (already in SVY21 in your file)\n",
    "hdb = pd.read_csv(PATH_HDB_CSV)\n",
    "\n",
    "# Confirm XY columns\n",
    "assert {\"X\", \"Y\"}.issubset(hdb.columns), \"Expected columns 'X' and 'Y' in HDB CSV.\"\n",
    "\n",
    "# Clean coordinate types\n",
    "hdb[\"X\"] = pd.to_numeric(hdb[\"X\"], errors=\"coerce\")\n",
    "hdb[\"Y\"] = pd.to_numeric(hdb[\"Y\"], errors=\"coerce\")\n",
    "hdb = hdb.dropna(subset=[\"X\", \"Y\"])\n",
    "\n",
    "# Build GeoDataFrame with EPSG:3414\n",
    "gdf_hdb = gpd.GeoDataFrame(hdb, geometry=gpd.points_from_xy(hdb[\"X\"], hdb[\"Y\"]), crs=TARGET_CRS)\n",
    "\n",
    "# Save to GeoJSON (or GPKG if you prefer)\n",
    "gdf_hdb.to_file(OUT_HDB, driver=\"GeoJSON\")\n",
    "print(f\"✅ HDB saved: {OUT_HDB}  |  rows={len(gdf_hdb)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9adae700-ad7b-4301-b68c-0eeae4a5b612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MRT saved: processed\\mrt_2024_points_3414.geojson  |  rows=563  |  crs=EPSG:3414\n"
     ]
    }
   ],
   "source": [
    "mrt_dir = unzip_to_dir(PATH_ZIP_MRT)\n",
    "mrt_shp = first_shp(mrt_dir)\n",
    "if mrt_shp is None:\n",
    "    raise FileNotFoundError(\"No .shp found in MRT zip.\")\n",
    "\n",
    "gdf_mrt = gpd.read_file(mrt_shp)\n",
    "gdf_mrt = reproject_gdf(gdf_mrt, TARGET_CRS)\n",
    "gdf_mrt[\"geometry\"] = gdf_mrt[\"geometry\"].apply(to_2d_geometry)\n",
    "\n",
    "# Standardize a name column if present\n",
    "if \"Name\" in gdf_mrt.columns and \"station_name\" not in gdf_mrt.columns:\n",
    "    gdf_mrt = gdf_mrt.rename(columns={\"Name\": \"station_name\"})\n",
    "\n",
    "gdf_mrt.to_file(OUT_MRT, driver=\"GeoJSON\")\n",
    "print(f\"✅ MRT saved: {OUT_MRT}  |  rows={len(gdf_mrt)}  |  crs={gdf_mrt.crs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb53493a-26d2-45fe-8d41-ded1ab54babc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Bus saved: processed\\bus_2025_points_3414.geojson  |  rows=5172  |  crs=EPSG:3414\n"
     ]
    }
   ],
   "source": [
    "bus_dir = unzip_to_dir(PATH_ZIP_BUS)\n",
    "bus_shp = first_shp(bus_dir)\n",
    "if bus_shp is None:\n",
    "    raise FileNotFoundError(\"No .shp found in Bus zip.\")\n",
    "\n",
    "gdf_bus = gpd.read_file(bus_shp)\n",
    "# Reproject if needed\n",
    "if str(gdf_bus.crs).lower() != TARGET_CRS.lower():\n",
    "    gdf_bus = gdf_bus.to_crs(TARGET_CRS)\n",
    "\n",
    "# Rename helpful fields (optional)\n",
    "rename_map = {}\n",
    "if \"BUS_STOP_N\" in gdf_bus.columns: rename_map[\"BUS_STOP_N\"] = \"bus_stop_no\"\n",
    "if \"LOC_DESC\"   in gdf_bus.columns: rename_map[\"LOC_DESC\"]   = \"desc\"\n",
    "if rename_map:\n",
    "    gdf_bus = gdf_bus.rename(columns=rename_map)\n",
    "\n",
    "gdf_bus.to_file(OUT_BUS, driver=\"GeoJSON\")\n",
    "print(f\"✅ Bus saved: {OUT_BUS}  |  rows={len(gdf_bus)}  |  crs={gdf_bus.crs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cac5feb8-6fd2-4228-a089-bf2ed3c3e356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Planning Areas saved: processed\\mp19_planning_areas_3414.geojson\n"
     ]
    }
   ],
   "source": [
    "# Uses a Fiona-based pipeline to avoid Shapely MultiPolygon array-interface hiccups\n",
    "robust_reproject_write_polygons_with_fiona(PATH_ZIP_PA, OUT_PA)\n",
    "print(f\"✅ Planning Areas saved: {OUT_PA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcbcadf0-6534-4b13-9114-568dd9bf8872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Subzones saved: processed\\mp19_subzones_3414.geojson\n"
     ]
    }
   ],
   "source": [
    "robust_reproject_write_polygons_with_fiona(PATH_ZIP_SZ, OUT_SZ)\n",
    "print(f\"✅ Subzones saved: {OUT_SZ}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "432b51c9-9a55-4640-9106-5d045aa02e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HDB': {'path': 'processed\\\\hdb_2023_points_3414.geojson',\n",
       "  'rows': 25760,\n",
       "  'crs': 'EPSG:3414',\n",
       "  'geom_types': ['Point']},\n",
       " 'MRT': {'path': 'processed\\\\mrt_2024_points_3414.geojson',\n",
       "  'rows': 563,\n",
       "  'crs': 'EPSG:3414',\n",
       "  'geom_types': ['Point']},\n",
       " 'Bus': {'path': 'processed\\\\bus_2025_points_3414.geojson',\n",
       "  'rows': 5172,\n",
       "  'crs': 'EPSG:3414',\n",
       "  'geom_types': ['Point']},\n",
       " 'PlanningAreas': {'path': 'processed\\\\mp19_planning_areas_3414.geojson',\n",
       "  'rows': 55,\n",
       "  'crs': 'EPSG:3414',\n",
       "  'geom_types': ['MultiPolygon']},\n",
       " 'Subzones': {'path': 'processed\\\\mp19_subzones_3414.geojson',\n",
       "  'rows': 332,\n",
       "  'crs': 'EPSG:3414',\n",
       "  'geom_types': ['MultiPolygon']}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload the GeoJSONs (optional) and print compact stats\n",
    "def layer_stats(path):\n",
    "    g = gpd.read_file(path)\n",
    "    return {\n",
    "        \"path\": str(path),\n",
    "        \"rows\": len(g),\n",
    "        \"crs\": str(g.crs),\n",
    "        \"geom_types\": list(g.geom_type.unique())\n",
    "    }\n",
    "\n",
    "report = {\n",
    "    \"HDB\": layer_stats(OUT_HDB),\n",
    "    \"MRT\": layer_stats(OUT_MRT),\n",
    "    \"Bus\": layer_stats(OUT_BUS),\n",
    "    \"PlanningAreas\": layer_stats(OUT_PA),\n",
    "    \"Subzones\": layer_stats(OUT_SZ),\n",
    "}\n",
    "\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe07ded-7f31-4a43-8b77-91503929229f",
   "metadata": {},
   "source": [
    "Preprocess Healthcare and Recreation Poltgon data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73589c38-909d-4c9b-b93c-2fe325b3a6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEALTH: (['LU_DESC_HEALTH & MEDICAL CARE'], [{'layer': 'LU_DESC_HEALTH & MEDICAL CARE', 'count': 198, 'crs': 'GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]', 'geometry_type': '3D Polygon', 'fields_sample': ['id', 'Name', 'description', 'timestamp', 'begin', 'end', 'altitudeMode', 'tessellate', 'extrude', 'visibility', 'drawOrder', 'icon']}])\n",
      "SPORTS: (['LU_DESC_SPORTS & RECREATION'], [{'layer': 'LU_DESC_SPORTS & RECREATION', 'count': 243, 'crs': 'GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]', 'geometry_type': '3D Polygon', 'fields_sample': ['id', 'Name', 'description', 'timestamp', 'begin', 'end', 'altitudeMode', 'tessellate', 'extrude', 'visibility', 'drawOrder', 'icon']}])\n",
      "Saved: processed\\health_polygons_3414.geojson processed\\health_centroids_3414.geojson\n",
      "Saved: processed\\sports_polygons_3414.geojson processed\\sports_centroids_3414.geojson\n"
     ]
    }
   ],
   "source": [
    "# INPUT GPKGs (edit paths if different)\n",
    "GPKG_HEALTH = \"data/SG_HEALTH & MEDICAL CARE.gpkg\"\n",
    "GPKG_SPORTS = \"data/SG_SPORTS & RECREATION.gpkg\"\n",
    "\n",
    "# Output folder\n",
    "OUT_DIR = Path(\"processed\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Target CRS (meters)\n",
    "TARGET_CRS = \"EPSG:3414\"\n",
    "\n",
    "# ---- Inspect helper (robust) ----\n",
    "def inspect_with_fiona(path):\n",
    "    layers = fiona.listlayers(path)\n",
    "    summaries = []\n",
    "    for lyr in layers:\n",
    "        with fiona.open(path, layer=lyr) as src:\n",
    "            crs = src.crs_wkt or src.crs\n",
    "            try:\n",
    "                crs_str = CRS.from_wkt(crs).to_string() if isinstance(crs, str) else CRS.from_user_input(crs).to_string()\n",
    "            except Exception:\n",
    "                crs_str = str(crs)\n",
    "            geom_type = src.schema.get(\"geometry\", \"Unknown\")\n",
    "            props = list(src.schema.get(\"properties\", {}).keys())\n",
    "            cnt = sum(1 for _ in src)\n",
    "            summaries.append({\"layer\": lyr, \"count\": cnt, \"crs\": crs_str,\n",
    "                              \"geometry_type\": geom_type, \"fields_sample\": props[:12]})\n",
    "    return layers, summaries\n",
    "\n",
    "print(\"HEALTH:\", inspect_with_fiona(GPKG_HEALTH))\n",
    "print(\"SPORTS:\", inspect_with_fiona(GPKG_SPORTS))\n",
    "\n",
    "# ---- Polygon centroid utils (no Shapely dependency) ----\n",
    "def polygon_centroid(coords):\n",
    "    # coords = [ring0, ring1, ...]; ring0 = outer ring [(x,y), ...]\n",
    "    if not coords or not coords[0]:\n",
    "        return None\n",
    "    ring = coords[0]\n",
    "    if ring[0] != ring[-1]:\n",
    "        ring = ring + [ring[0]]\n",
    "    A = Cx = Cy = 0.0\n",
    "    for i in range(len(ring)-1):\n",
    "        x0,y0 = ring[i]; x1,y1 = ring[i+1]\n",
    "        cross = x0*y1 - x1*y0\n",
    "        A += cross; Cx += (x0 + x1)*cross; Cy += (y0 + y1)*cross\n",
    "    if A == 0:\n",
    "        xs = [p[0] for p in ring[:-1]]; ys = [p[1] for p in ring[:-1]]\n",
    "        return (sum(xs)/len(xs), sum(ys)/len(ys))\n",
    "    A *= 0.5; Cx /= (6*A); Cy /= (6*A)\n",
    "    return (Cx, Cy)\n",
    "\n",
    "def multipolygon_centroid(multi_coords):\n",
    "    # area-weighted centroid across polygons\n",
    "    total_A = Cx_sum = Cy_sum = 0.0\n",
    "    for poly in multi_coords:\n",
    "        ring = poly[0] if poly else None\n",
    "        if not ring: \n",
    "            continue\n",
    "        if ring[0] != ring[-1]:\n",
    "            ring = ring + [ring[0]]\n",
    "        A = Cx = Cy = 0.0\n",
    "        for i in range(len(ring)-1):\n",
    "            x0,y0 = ring[i]; x1,y1 = ring[i+1]\n",
    "            cross = x0*y1 - x1*y0\n",
    "            A += cross; Cx += (x0 + x1)*cross; Cy += (y0 + y1)*cross\n",
    "        A *= 0.5\n",
    "        if A == 0: \n",
    "            continue\n",
    "        Cx /= (6*A); Cy /= (6*A)\n",
    "        total_A += abs(A); Cx_sum += Cx*abs(A); Cy_sum += Cy*abs(A)\n",
    "    if total_A == 0:\n",
    "        return None\n",
    "    return (Cx_sum/total_A, Cy_sum/total_A)\n",
    "\n",
    "def reproject_write_polygons_and_centroids(src_gpkg, src_layer, out_poly_path, out_pts_path):\n",
    "    with fiona.open(src_gpkg, layer=src_layer) as src:\n",
    "        transformer = Transformer.from_crs(src.crs_wkt or src.crs, TARGET_CRS, always_xy=True)\n",
    "        # Polygon writer (MultiPolygon schema)\n",
    "        schema_poly = {\"geometry\":\"MultiPolygon\", \"properties\": {k: v for k,v in src.schema[\"properties\"].items()}}\n",
    "        with fiona.open(out_poly_path, mode=\"w\", driver=\"GeoJSON\", crs=TARGET_CRS, schema=schema_poly) as dst_poly, \\\n",
    "             fiona.open(out_pts_path,  mode=\"w\", driver=\"GeoJSON\", crs=TARGET_CRS,\n",
    "                        schema={\"geometry\":\"Point\",\"properties\":schema_poly[\"properties\"]}) as dst_pt:\n",
    "            for feat in src:\n",
    "                geom = feat[\"geometry\"]\n",
    "                if geom is None:\n",
    "                    continue\n",
    "                # normalize to MultiPolygon\n",
    "                if geom[\"type\"] == \"Polygon\":\n",
    "                    mcoords = [geom[\"coordinates\"]]\n",
    "                elif geom[\"type\"] == \"MultiPolygon\":\n",
    "                    mcoords = geom[\"coordinates\"]\n",
    "                else:\n",
    "                    continue  # skip non-polygons\n",
    "                # transform coords to 3414 + drop Z\n",
    "                mcoords_tx = []\n",
    "                for poly in mcoords:\n",
    "                    poly_tx = []\n",
    "                    for ring in poly:\n",
    "                        ring_tx = []\n",
    "                        for c in ring:\n",
    "                            X,Y = transformer.transform(c[0], c[1])\n",
    "                            ring_tx.append((X, Y))\n",
    "                        poly_tx.append(ring_tx)\n",
    "                    mcoords_tx.append(poly_tx)\n",
    "                # write polygon\n",
    "                dst_poly.write({\"geometry\": {\"type\":\"MultiPolygon\", \"coordinates\": mcoords_tx},\n",
    "                                \"properties\": feat[\"properties\"]})\n",
    "                # area-weighted centroid (in 3414)\n",
    "                cen = multipolygon_centroid(mcoords_tx)\n",
    "                if cen is not None:\n",
    "                    dst_pt.write({\"geometry\": {\"type\":\"Point\", \"coordinates\": cen},\n",
    "                                  \"properties\": feat[\"properties\"]})\n",
    "\n",
    "# ---- Run for HEALTH ----\n",
    "OUT_HEALTH_POLY = OUT_DIR / \"health_polygons_3414.geojson\"\n",
    "OUT_HEALTH_PTS  = OUT_DIR / \"health_centroids_3414.geojson\"\n",
    "reproject_write_polygons_and_centroids(GPKG_HEALTH, \"LU_DESC_HEALTH & MEDICAL CARE\",\n",
    "                                       OUT_HEALTH_POLY, OUT_HEALTH_PTS)\n",
    "print(\"Saved:\", OUT_HEALTH_POLY, OUT_HEALTH_PTS)\n",
    "\n",
    "# ---- Run for SPORTS ----\n",
    "OUT_SPORTS_POLY = OUT_DIR / \"sports_polygons_3414.geojson\"\n",
    "OUT_SPORTS_PTS  = OUT_DIR / \"sports_centroids_3414.geojson\"\n",
    "reproject_write_polygons_and_centroids(GPKG_SPORTS, \"LU_DESC_SPORTS & RECREATION\",\n",
    "                                       OUT_SPORTS_POLY, OUT_SPORTS_PTS)\n",
    "print(\"Saved:\", OUT_SPORTS_POLY, OUT_SPORTS_PTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b4157c-0281-4030-b222-f95b4aa5612d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
