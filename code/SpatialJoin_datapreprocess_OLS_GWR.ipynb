{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e69b1944-6957-4e28-b884-30cd06cdd43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c895cdd5-0080-4c13-b0d2-0ef20f9c1202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ paths ------------\n",
    "hdb_parquet = \"processed_n/hdb_ols.parquet\"   \n",
    "subzone_shp = \"data/master-plan-2019-subzone_landuse_area.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a911b28a-105a-422f-b2d0-5edfeaf9047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ load HDB transactions ------------\n",
    "# Requires pyarrow or fastparquet. Install one if needed:\n",
    "# pip install pyarrow\n",
    "df = pd.read_parquet(hdb_parquet)\n",
    "\n",
    "# If your Parquet is already a GeoDataFrame with point geometry, keep it.\n",
    "# Otherwise, build point geometry from lon/lat columns (auto-detect common names).\n",
    "if isinstance(df, gpd.GeoDataFrame) and \"geometry\" in df.columns:\n",
    "    gdf_points = df.copy()\n",
    "    if gdf_points.crs is None:\n",
    "        # assume WGS84 if CRS missing\n",
    "        gdf_points = gdf_points.set_crs(4326)\n",
    "else:\n",
    "    # Guess lon/lat column names\n",
    "    lon_candidates = [c for c in df.columns if c.lower() in (\"lon\",\"lng\",\"longitude\",\"x\",\"long\")]\n",
    "    lat_candidates = [c for c in df.columns if c.lower() in (\"lat\",\"latitude\",\"y\")]\n",
    "    if not lon_candidates or not lat_candidates:\n",
    "        raise ValueError(\n",
    "            \"Could not find longitude/latitude columns. \"\n",
    "            \"Please ensure columns like lon/lng/longitude and lat/latitude exist.\"\n",
    "        )\n",
    "    lon_col, lat_col = lon_candidates[0], lat_candidates[0]\n",
    "    gdf_points = gpd.GeoDataFrame(\n",
    "        df.copy(),\n",
    "        geometry=gpd.points_from_xy(df[lon_col], df[lat_col]),\n",
    "        crs=4326\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b7596a6-27cf-4db7-961f-8af805b8aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ load Subzones ------------\n",
    "subzones = gpd.read_file(subzone_shp)\n",
    "\n",
    "# Try to fix any invalid polygon geometries\n",
    "try:\n",
    "    subzones[\"geometry\"] = subzones.buffer(0)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Find a good name column in the subzones layer\n",
    "name_candidates = [\"SUBZONE_N\", \"SUBZONE_NAME\", \"SUBZONE\", \"Name\", \"name\"]\n",
    "subzone_name_col = next((c for c in name_candidates if c in subzones.columns), None)\n",
    "if subzone_name_col is None:\n",
    "    # fallback to first non-geometry column\n",
    "    subzone_name_col = [c for c in subzones.columns if c != \"geometry\"][0]\n",
    "\n",
    "# Carry polygon geometry through the join by duplicating it into a data column\n",
    "subzones = subzones.copy()\n",
    "subzones[\"subzone_geom\"] = subzones.geometry  # will be retained as an attribute during sjoin\n",
    "subzones = subzones[[subzone_name_col, \"subzone_geom\", \"geometry\"]].rename(\n",
    "    columns={subzone_name_col: \"subzone_name\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdd228ca-1620-4ceb-90db-6059c8e5d064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ match CRS & spatial join ------------\n",
    "if subzones.crs is None:\n",
    "    # MP19 layers are usually SVY21 / EPSG:3414; set if missing\n",
    "    subzones = subzones.set_crs(3414)\n",
    "\n",
    "if gdf_points.crs != subzones.crs:\n",
    "    gdf_points = gdf_points.to_crs(subzones.crs)\n",
    "\n",
    "# point-in-polygon join (keeps point geometry as the main 'geometry')\n",
    "joined = gpd.sjoin(\n",
    "    gdf_points,\n",
    "    subzones,\n",
    "    how=\"left\",\n",
    "    predicate=\"within\",\n",
    ")\n",
    "\n",
    "# Clean up sjoin helper columns\n",
    "for c in list(joined.columns):\n",
    "    if c.startswith(\"index_\"):\n",
    "        joined.drop(columns=c, inplace=True, errors=\"ignore\")\n",
    "\n",
    "# Ensure the two required columns are present and at the front\n",
    "front = [\"subzone_name\", \"subzone_geom\"]\n",
    "ordered_cols = front + [c for c in joined.columns if c not in front]\n",
    "joined = joined[ordered_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7f486eb-68ed-4014-8113-d4ad5ee5814b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Subzone name field used: subzone_name\n",
      "Saved: processed_n/hdb_features_with_subzone_geometry.parquet\n"
     ]
    }
   ],
   "source": [
    "# ------------ save outputs ------------\n",
    "# 1) GeoParquet (preserves point geometry and subzone_geom column)\n",
    "out_parquet = \"processed_n/hdb_features_with_subzone_geometry.parquet\"\n",
    "joined.to_parquet(out_parquet, index=False)\n",
    "\n",
    "# # 2) CSV (drops geometry columns for light sharing)\n",
    "# out_csv = \"processed_n/hdb_features_with_subzone_light.csv\"\n",
    "# joined.drop(columns=[\"geometry\", \"subzone_geom\"], errors=\"ignore\").to_csv(out_csv, index=False)\n",
    "\n",
    "# 3) Optional: GeoPackage (widely compatible). Saves *point* layer; polygon geometry is kept as an attribute column.\n",
    "# Comment out if you don't need it.\n",
    "# out_gpkg = \"processed_n/hdb_features_with_subzone.gpkg\"\n",
    "# joined.to_file(out_gpkg, layer=\"hdb_with_subzone\", driver=\"GPKG\")\n",
    "\n",
    "print(\"Done.\")\n",
    "print(\"Subzone name field used:\", \"subzone_name\")\n",
    "print(\"Saved:\", out_parquet)\n",
    "# print(\"Saved:\", out_csv)\n",
    "# print(\"Saved:\", out_gpkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8beb3b42-9ab0-4231-83d8-468b8bd0794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "join_hdb_data = \"processed_n/hdb_features_with_subzone_geometry.parquet\"\n",
    "df_1 = gpd.read_parquet(join_hdb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9147b1ce-48a3-4a41-8ac8-749f3d9b4cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subzone_name</th>\n",
       "      <th>subzone_geom</th>\n",
       "      <th>month</th>\n",
       "      <th>town</th>\n",
       "      <th>flat_type</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>flat_model</th>\n",
       "      <th>lease_commence_date</th>\n",
       "      <th>resale_price</th>\n",
       "      <th>...</th>\n",
       "      <th>model_Model A2</th>\n",
       "      <th>model_Multi Generation</th>\n",
       "      <th>model_New Generation</th>\n",
       "      <th>model_Premium Apartment</th>\n",
       "      <th>model_Premium Apartment Loft</th>\n",
       "      <th>model_Simplified</th>\n",
       "      <th>model_Standard</th>\n",
       "      <th>model_Terrace</th>\n",
       "      <th>model_Type S1</th>\n",
       "      <th>model_Type S2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHONG BOON</td>\n",
       "      <td>POLYGON Z ((30676.168 39006.867 0, 30761.414 3...</td>\n",
       "      <td>2023-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>2 ROOM</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Improved</td>\n",
       "      <td>1979</td>\n",
       "      <td>267000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TOWNSVILLE</td>\n",
       "      <td>POLYGON Z ((29649.875 38978.996 0, 29671.324 3...</td>\n",
       "      <td>2023-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>2 ROOM</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Improved</td>\n",
       "      <td>1977</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  subzone_name                                       subzone_geom    month  \\\n",
       "0   CHONG BOON  POLYGON Z ((30676.168 39006.867 0, 30761.414 3...  2023-01   \n",
       "1   TOWNSVILLE  POLYGON Z ((29649.875 38978.996 0, 29671.324 3...  2023-01   \n",
       "\n",
       "         town flat_type storey_range  floor_area_sqm flat_model  \\\n",
       "0  ANG MO KIO    2 ROOM     01 TO 03            44.0   Improved   \n",
       "1  ANG MO KIO    2 ROOM     04 TO 06            49.0   Improved   \n",
       "\n",
       "   lease_commence_date  resale_price  ...  model_Model A2  \\\n",
       "0                 1979      267000.0  ...             0.0   \n",
       "1                 1977      300000.0  ...             0.0   \n",
       "\n",
       "   model_Multi Generation  model_New Generation  model_Premium Apartment  \\\n",
       "0                     0.0                   0.0                      0.0   \n",
       "1                     0.0                   0.0                      0.0   \n",
       "\n",
       "   model_Premium Apartment Loft  model_Simplified model_Standard  \\\n",
       "0                           0.0               0.0            0.0   \n",
       "1                           0.0               0.0            0.0   \n",
       "\n",
       "   model_Terrace  model_Type S1  model_Type S2  \n",
       "0            0.0            0.0            0.0  \n",
       "1            0.0            0.0            0.0  \n",
       "\n",
       "[2 rows x 48 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a7164e6-c877-4381-8758-88ddb8b29f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subzone_name', 'subzone_geom', 'month', 'town', 'flat_type',\n",
       "       'storey_range', 'floor_area_sqm', 'flat_model', 'lease_commence_date',\n",
       "       'resale_price', 'resale_year', 'resale_age', 'LAT', 'LNG', 'X', 'Y',\n",
       "       'geometry', 'log_price', 'dist_mrt', 'dist_hcen', 'dist_scen',\n",
       "       'bus_count_400m', 'storey_mid', 'type_2 ROOM', 'type_3 ROOM',\n",
       "       'type_4 ROOM', 'type_5 ROOM', 'type_EXECUTIVE', 'type_MULTI-GENERATION',\n",
       "       'model_3Gen', 'model_Adjoined flat', 'model_Apartment', 'model_DBSS',\n",
       "       'model_Improved', 'model_Improved-Maisonette', 'model_Maisonette',\n",
       "       'model_Model A', 'model_Model A-Maisonette', 'model_Model A2',\n",
       "       'model_Multi Generation', 'model_New Generation',\n",
       "       'model_Premium Apartment', 'model_Premium Apartment Loft',\n",
       "       'model_Simplified', 'model_Standard', 'model_Terrace', 'model_Type S1',\n",
       "       'model_Type S2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.columns.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42c03f77-e695-4e62-a8e8-2d28a626bd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\METAYJ\\AppData\\Local\\Temp\\ipykernel_47580\\2572579072.py:48: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  .apply(lambda s: s.unary_union)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      " - processed_n/subzone_level_ols_coefficients_wide.gpkg\n",
      "     subzone_name  n_obs        R2    Adj_R2     const  dist_mrt  dist_hcen  \\\n",
      "0       ADMIRALTY     93  0.969211  0.964593  8.743540  0.000161  -0.000201   \n",
      "1  ALEXANDRA HILL     71  0.984519  0.980297  9.099769  0.000376   0.000030   \n",
      "2        ALJUNIED    174  0.973979  0.971143  9.992028 -0.000225   0.000031   \n",
      "3      ANCHORVALE    385  0.914311  0.910585  9.384674  0.000056   0.000104   \n",
      "4       BALESTIER    222  0.979386  0.977885  9.283172 -0.000086   0.000019   \n",
      "\n",
      "   dist_scen  bus_count_400m  resale_age  ...  model_Multi Generation  \\\n",
      "0   0.000062        0.002110   -0.005458  ...                     0.0   \n",
      "1  -0.000594        0.004871   -0.012904  ...                     0.0   \n",
      "2  -0.000200       -0.000154   -0.011066  ...                     0.0   \n",
      "3  -0.000005        0.000598   -0.013421  ...                     0.0   \n",
      "4   0.000088       -0.001503   -0.009023  ...                     0.0   \n",
      "\n",
      "   model_New Generation  model_Premium Apartment  \\\n",
      "0              0.000000                 0.000000   \n",
      "1              1.462387                 0.000000   \n",
      "2              1.257355                 0.000000   \n",
      "3              0.000000                 1.561139   \n",
      "4              1.153857                 0.000000   \n",
      "\n",
      "   model_Premium Apartment Loft  model_Simplified  model_Standard  \\\n",
      "0                           0.0          0.000000        0.000000   \n",
      "1                           0.0          1.541634        1.501070   \n",
      "2                           0.0          0.000000        1.209633   \n",
      "3                           0.0          0.000000        0.000000   \n",
      "4                           0.0          1.093671        1.033230   \n",
      "\n",
      "   model_Terrace  model_Type S1  model_Type S2  \\\n",
      "0        0.00000            0.0            0.0   \n",
      "1        0.00000            0.0            0.0   \n",
      "2        0.00000            0.0            0.0   \n",
      "3        0.00000            0.0            0.0   \n",
      "4        1.88189            0.0            0.0   \n",
      "\n",
      "                                            geometry  \n",
      "0  POLYGON Z ((27468.829 48929.475 0, 27487.489 4...  \n",
      "1  POLYGON Z ((25899.699 29766.744 0, 25886.223 2...  \n",
      "2  POLYGON Z ((34449.129 33730.191 0, 34478.687 3...  \n",
      "3  POLYGON Z ((34908.045 42246.934 0, 34457.047 4...  \n",
      "4  POLYGON Z ((31228.813 34642.051 0, 31212.48 34...  \n",
      "\n",
      "[5 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Full coefficient table per subzone (with geometry export)\n",
    "# ============================================================\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from shapely.geometry import MultiPoint\n",
    "\n",
    "# --------- columns ---------\n",
    "Y = \"log_price\"\n",
    "X_vars = [\n",
    "    \"dist_mrt\", \"dist_hcen\", \"dist_scen\", \"bus_count_400m\", \"resale_age\", \"storey_mid\", \"floor_area_sqm\",\n",
    "    \"type_2 ROOM\", \"type_3 ROOM\", \"type_4 ROOM\", \"type_5 ROOM\", \"type_EXECUTIVE\", \"type_MULTI-GENERATION\",\n",
    "    \"model_3Gen\", \"model_Adjoined flat\", \"model_Apartment\", \"model_DBSS\", \"model_Improved\",\n",
    "    \"model_Improved-Maisonette\", \"model_Maisonette\", \"model_Model A\", \"model_Model A-Maisonette\",\n",
    "    \"model_Model A2\", \"model_Multi Generation\", \"model_New Generation\", \"model_Premium Apartment\",\n",
    "    \"model_Premium Apartment Loft\", \"model_Simplified\", \"model_Standard\", \"model_Terrace\",\n",
    "    \"model_Type S1\", \"model_Type S2\"\n",
    "]\n",
    "\n",
    "# --------- ensure GeoDataFrame & decode WKB if needed ---------\n",
    "df1 = df_1.copy()\n",
    "\n",
    "# decode point geometry from WKB if necessary\n",
    "if not isinstance(df1, gpd.GeoDataFrame):\n",
    "    df1[\"geometry\"] = gpd.GeoSeries.from_wkb(df1[\"geometry\"])\n",
    "    df1 = gpd.GeoDataFrame(df1, geometry=\"geometry\")\n",
    "\n",
    "# decode polygon geometry from WKB if necessary\n",
    "if \"subzone_geom\" in df1.columns and df1[\"subzone_geom\"].notna().any():\n",
    "    if df1[\"subzone_geom\"].dtype == object and isinstance(df1[\"subzone_geom\"].dropna().iloc[0], (bytes, bytearray)):\n",
    "        df1[\"subzone_geom\"] = gpd.GeoSeries.from_wkb(df1[\"subzone_geom\"])\n",
    "\n",
    "# set CRS if missing (MP19 is usually EPSG:3414)\n",
    "if df1.crs is None:\n",
    "    df1.set_crs(epsg=3414, inplace=True)\n",
    "\n",
    "# --------- representative geometry per subzone ---------\n",
    "subzone_geoms = {}\n",
    "\n",
    "has_poly = \"subzone_geom\" in df1.columns and df1[\"subzone_geom\"].notna().any()\n",
    "if has_poly:\n",
    "    poly = (\n",
    "        df1.loc[df1[\"subzone_geom\"].notna(), [\"subzone_name\", \"subzone_geom\"]]\n",
    "        .drop_duplicates(subset=[\"subzone_name\", \"subzone_geom\"])\n",
    "        .groupby(\"subzone_name\")[\"subzone_geom\"]\n",
    "        .apply(lambda s: s.unary_union)\n",
    "        .reset_index()\n",
    "        .rename(columns={\"subzone_geom\": \"geometry\"})\n",
    "    )\n",
    "    poly_gdf = gpd.GeoDataFrame(poly, geometry=\"geometry\", crs=df1.crs)\n",
    "    subzone_geoms = dict(zip(poly_gdf[\"subzone_name\"], poly_gdf[\"geometry\"]))\n",
    "\n",
    "# fallback: convex hull of the points\n",
    "for sz, g in df1.groupby(\"subzone_name\"):\n",
    "    if sz not in subzone_geoms or subzone_geoms[sz] is None:\n",
    "        pts = [geom for geom in g.geometry.values if geom is not None]\n",
    "        if len(pts) >= 3:\n",
    "            subzone_geoms[sz] = MultiPoint(pts).convex_hull\n",
    "        elif len(pts) > 0:\n",
    "            subzone_geoms[sz] = MultiPoint(pts).envelope\n",
    "\n",
    "# --------- fit OLS per subzone & collect coefficients ---------\n",
    "coeff_rows = []   # wide table rows\n",
    "tidy_rows  = []   # long/tidy rows\n",
    "min_n = len(X_vars) + 5\n",
    "\n",
    "for sz, sub in df1.groupby(\"subzone_name\"):\n",
    "    sub = sub[[Y] + X_vars].dropna()\n",
    "    if len(sub) < min_n:\n",
    "        continue\n",
    "    try:\n",
    "        X = sm.add_constant(sub[X_vars])\n",
    "        y = sub[Y]\n",
    "        model = sm.OLS(y, X).fit()\n",
    "    except Exception:\n",
    "        # skip ill-conditioned groups\n",
    "        continue\n",
    "\n",
    "    # ---- wide row: one column per parameter ----\n",
    "    row = {\"subzone_name\": sz, \"n_obs\": len(sub), \"R2\": model.rsquared, \"Adj_R2\": model.rsquared_adj}\n",
    "    for param, val in model.params.items():\n",
    "        row[param] = val\n",
    "    coeff_rows.append(row)\n",
    "\n",
    "    # ---- tidy rows: one row per coefficient ----\n",
    "    for param, val in model.params.items():\n",
    "        tidy_rows.append({\n",
    "            \"subzone_name\": sz,\n",
    "            \"n_obs\": len(sub),\n",
    "            \"term\": param,\n",
    "            \"coef\": float(val),\n",
    "            \"std_err\": float(model.bse.get(param, np.nan)),\n",
    "            \"t\": float(model.tvalues.get(param, np.nan)),\n",
    "            \"pval\": float(model.pvalues.get(param, np.nan))\n",
    "        })\n",
    "\n",
    "# --------- build DataFrames ---------\n",
    "coeff_wide = pd.DataFrame(coeff_rows).set_index(\"subzone_name\").sort_index()\n",
    "coeff_tidy = pd.DataFrame(tidy_rows).sort_values([\"subzone_name\", \"term\"]).reset_index(drop=True)\n",
    "\n",
    "# attach geometry to wide table\n",
    "geo_df = coeff_wide.reset_index()\n",
    "geo_df[\"geometry\"] = geo_df[\"subzone_name\"].map(subzone_geoms)\n",
    "gcoeff_wide = gpd.GeoDataFrame(geo_df, geometry=\"geometry\", crs=df1.crs).dropna(subset=[\"geometry\"])\n",
    "\n",
    "# --------- save outputs ---------\n",
    "# CSVs (no geometry)\n",
    "coeff_wide.to_csv(\"processed_n/subzone_level_ols_coefficients_wide.csv\", index=True)\n",
    "coeff_tidy.to_csv(\"processed_n/subzone_level_ols_coefficients_tidy.csv\", index=False)\n",
    "\n",
    "# GeoPackage + GeoParquet (with geometry)\n",
    "gcoeff_wide.to_file(\"processed_n/subzone_level_ols_coefficients_wide.gpkg\", driver=\"GPKG\")\n",
    "# gcoeff_wide.to_parquet(\"processed_n/subzone_level_ols_coefficients_wide.parquet\", index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "# print(\" - processed_n/subzone_level_ols_coefficients_wide.csv\")\n",
    "# print(\" - processed_n/subzone_level_ols_coefficients_tidy.csv\")\n",
    "print(\" - processed_n/subzone_level_ols_coefficients_wide.gpkg\")\n",
    "# print(\" - processed_n/subzone_level_ols_coefficients_wide.parquet\")\n",
    "print(gcoeff_wide.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134a996b-8e1c-409b-afd1-4c9975b70c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ============================================================\n",
    "# # OLS per subzone + attach geometry (GeoParquet output)\n",
    "# # ============================================================\n",
    "# import pandas as pd\n",
    "# import geopandas as gpd\n",
    "# import numpy as np\n",
    "# import statsmodels.api as sm\n",
    "# from shapely.geometry import MultiPoint\n",
    "\n",
    "# # ------- Columns -------\n",
    "# Y = \"log_price\"\n",
    "# X_vars = [\n",
    "#     \"dist_mrt\", \"dist_hcen\", \"dist_scen\", \"bus_count_400m\", \"resale_age\", \"storey_mid\",\n",
    "#     \"type_2 ROOM\", \"type_3 ROOM\", \"type_4 ROOM\", \"type_5 ROOM\", \"type_EXECUTIVE\", \"type_MULTI-GENERATION\",\n",
    "#     \"model_3Gen\", \"model_Adjoined flat\", \"model_Apartment\", \"model_DBSS\", \"model_Improved\",\n",
    "#     \"model_Improved-Maisonette\", \"model_Maisonette\", \"model_Model A\", \"model_Model A-Maisonette\",\n",
    "#     \"model_Model A2\", \"model_Multi Generation\", \"model_New Generation\", \"model_Premium Apartment\",\n",
    "#     \"model_Premium Apartment Loft\", \"model_Simplified\", \"model_Standard\", \"model_Terrace\",\n",
    "#     \"model_Type S1\", \"model_Type S2\"\n",
    "# ]\n",
    "\n",
    "# # ------- Ensure GeoDataFrame + decode WKB if needed -------\n",
    "# df1 = df_1.copy()\n",
    "\n",
    "# # Decode main 'geometry' (points) if it looks like WKB (bytes)\n",
    "# if not isinstance(df1, gpd.GeoDataFrame):\n",
    "#     try:\n",
    "#         df1[\"geometry\"] = gpd.GeoSeries.from_wkb(df1[\"geometry\"])\n",
    "#         df1 = gpd.GeoDataFrame(df1, geometry=\"geometry\")\n",
    "#     except Exception as e:\n",
    "#         raise ValueError(\"Failed to interpret 'geometry' column as WKB/geometry.\") from e\n",
    "\n",
    "# # Decode 'subzone_geom' (polygons) if stored as WKB bytes\n",
    "# if \"subzone_geom\" in df1.columns and df1[\"subzone_geom\"].notna().any():\n",
    "#     if df1[\"subzone_geom\"].dtype == object and isinstance(df1[\"subzone_geom\"].dropna().iloc[0], (bytes, bytearray)):\n",
    "#         df1[\"subzone_geom\"] = gpd.GeoSeries.from_wkb(df1[\"subzone_geom\"])\n",
    "\n",
    "# # Set/keep CRS (Master Plan 2019 is typically EPSG:3414)\n",
    "# if df1.crs is None:\n",
    "#     df1.set_crs(epsg=3414, inplace=True)\n",
    "\n",
    "# # ------- Build a representative geometry per subzone -------\n",
    "# subzone_geoms = {}\n",
    "\n",
    "# has_poly = \"subzone_geom\" in df1.columns and df1[\"subzone_geom\"].notna().any()\n",
    "\n",
    "# if has_poly:\n",
    "#     # dissolve available polygons by subzone_name\n",
    "#     poly = (\n",
    "#         df1.loc[df1[\"subzone_geom\"].notna(), [\"subzone_name\", \"subzone_geom\"]]\n",
    "#         .drop_duplicates(subset=[\"subzone_name\", \"subzone_geom\"])\n",
    "#         .groupby(\"subzone_name\")[\"subzone_geom\"]\n",
    "#         .apply(lambda s: s.unary_union)\n",
    "#         .reset_index()\n",
    "#         .rename(columns={\"subzone_geom\": \"geometry\"})\n",
    "#     )\n",
    "#     poly_gdf = gpd.GeoDataFrame(poly, geometry=\"geometry\", crs=df1.crs)\n",
    "#     subzone_geoms = dict(zip(poly_gdf[\"subzone_name\"], poly_gdf[\"geometry\"]))\n",
    "\n",
    "# # fallback: convex hull of transaction points when polygon missing\n",
    "# for sz, g in df1.groupby(\"subzone_name\"):\n",
    "#     if sz not in subzone_geoms or subzone_geoms[sz] is None:\n",
    "#         pts = [geom for geom in g.geometry.values if geom is not None]\n",
    "#         if len(pts) >= 3:\n",
    "#             subzone_geoms[sz] = MultiPoint(pts).convex_hull\n",
    "#         elif len(pts) > 0:\n",
    "#             # hull not defined for <3 points—use point buffer(0) (degenerate) or the point itself\n",
    "#             subzone_geoms[sz] = MultiPoint(pts).envelope\n",
    "\n",
    "# # ------- OLS per subzone + collect metrics -------\n",
    "# results_rows = []\n",
    "# min_n = len(X_vars) + 5   # simple safeguard against underspecified models\n",
    "\n",
    "# for sz, sub in df1.groupby(\"subzone_name\"):\n",
    "#     sub = sub[[Y] + X_vars].dropna()\n",
    "#     if len(sub) < min_n:\n",
    "#         continue\n",
    "\n",
    "#     X = sm.add_constant(sub[X_vars])\n",
    "#     y = sub[Y]\n",
    "#     model = sm.OLS(y, X).fit()\n",
    "\n",
    "#     results_rows.append({\n",
    "#         \"subzone_name\": sz,\n",
    "#         \"n_obs\": len(sub),\n",
    "#         \"R2\": model.rsquared,\n",
    "#         \"Adj_R2\": model.rsquared_adj,\n",
    "#         \"AIC\": model.aic,\n",
    "#         \"BIC\": model.bic,\n",
    "#         \"F_pval\": model.f_pvalue\n",
    "#     })\n",
    "\n",
    "# # ------- Attach geometry & save as GeoParquet -------\n",
    "# results_df = pd.DataFrame(results_rows).sort_values(\"R2\", ascending=False)\n",
    "# results_df[\"geometry\"] = results_df[\"subzone_name\"].map(subzone_geoms)\n",
    "\n",
    "# gresults = gpd.GeoDataFrame(results_df, geometry=\"geometry\", crs=df1.crs)\n",
    "# gresults = gresults.dropna(subset=[\"geometry\"]).reset_index(drop=True)\n",
    "\n",
    "# # out_parquet = \"processed_n/subzone_level_ols_summary.parquet\"\n",
    "# # gresults.to_parquet(out_parquet, index=False)\n",
    "\n",
    "# # ---------- Save as GeoPackage (.gpkg) ----------\n",
    "# out_gpkg = \"processed_n/subzone_level_ols_summary.gpkg\"\n",
    "\n",
    "# # The 'driver' argument tells GeoPandas to use the GPKG format\n",
    "# gresults.to_file(out_gpkg, driver=\"GPKG\")\n",
    "\n",
    "# print(f\"Saved GeoPackage: {out_gpkg}\")\n",
    "\n",
    "\n",
    "# # print(f\"Saved GeoParquet: {out_parquet}\")\n",
    "# # print(gresults.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e1d925-b74f-419b-9241-ea823595dff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gresults.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2233ae-9435-4529-a4eb-23dc257e44a4",
   "metadata": {},
   "source": [
    "#### GWR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27970150-3512-4bfe-9dd6-a6f5eb935f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subzone_name', 'subzone_geom', 'month', 'town', 'flat_type',\n",
       "       'storey_range', 'floor_area_sqm', 'flat_model', 'lease_commence_date',\n",
       "       'resale_price', 'resale_year', 'resale_age', 'LAT', 'LNG', 'X', 'Y',\n",
       "       'geometry', 'log_price', 'dist_mrt', 'dist_hcen', 'dist_scen',\n",
       "       'bus_count_400m', 'storey_mid', 'type_2 ROOM', 'type_3 ROOM',\n",
       "       'type_4 ROOM', 'type_5 ROOM', 'type_EXECUTIVE', 'type_MULTI-GENERATION',\n",
       "       'model_3Gen', 'model_Adjoined flat', 'model_Apartment', 'model_DBSS',\n",
       "       'model_Improved', 'model_Improved-Maisonette', 'model_Maisonette',\n",
       "       'model_Model A', 'model_Model A-Maisonette', 'model_Model A2',\n",
       "       'model_Multi Generation', 'model_New Generation',\n",
       "       'model_Premium Apartment', 'model_Premium Apartment Loft',\n",
       "       'model_Simplified', 'model_Standard', 'model_Terrace', 'model_Type S1',\n",
       "       'model_Type S2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.columns.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f73fe8f-7e9d-4aa3-a922-b77710ad1c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mgwr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1098bc20-5e15-4813-9330-a929982e72a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected bandwidth: 516.0\n",
      "AICc: -72261.306, RSS: 85.806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\METAYJ\\AppData\\Local\\Temp\\ipykernel_47580\\760342510.py:162: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  .groupby(\"subzone_name\")[\"subzone_geom\"].apply(lambda s: s.unary_union)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GWR completed successfully and files saved.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Robust GWR per-point + subzone aggregation (version-safe)\n",
    "# ============================================================\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from shapely.geometry import MultiPoint\n",
    "import warnings\n",
    "from mgwr.gwr import GWR\n",
    "from mgwr.sel_bw import Sel_BW\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# -------- Configuration --------\n",
    "Y = \"log_price\"\n",
    "X_vars = [\n",
    "    \"dist_mrt\", \"dist_hcen\", \"dist_scen\", \"bus_count_400m\", \"resale_age\", \"storey_mid\", \"floor_area_sqm\"]\n",
    "\n",
    "# ============================================================\n",
    "# 1) Prepare data\n",
    "# ============================================================\n",
    "df1 = df_1.copy()\n",
    "\n",
    "# Decode WKB → geometry\n",
    "if not isinstance(df1, gpd.GeoDataFrame):\n",
    "    df1[\"geometry\"] = gpd.GeoSeries.from_wkb(df1[\"geometry\"])\n",
    "    df1 = gpd.GeoDataFrame(df1, geometry=\"geometry\")\n",
    "\n",
    "if \"subzone_geom\" in df1.columns and df1[\"subzone_geom\"].notna().any():\n",
    "    if isinstance(df1[\"subzone_geom\"].dropna().iloc[0], (bytes, bytearray)):\n",
    "        df1[\"subzone_geom\"] = gpd.GeoSeries.from_wkb(df1[\"subzone_geom\"])\n",
    "\n",
    "# Ensure projected CRS (EPSG:3414)\n",
    "if df1.crs is None:\n",
    "    df1.set_crs(3414, inplace=True)\n",
    "elif df1.crs.to_epsg() != 3414:\n",
    "    df1 = df1.to_crs(3414)\n",
    "\n",
    "# Keep complete cases\n",
    "cols_needed = [Y] + X_vars + [\"subzone_name\", \"geometry\"]\n",
    "df1 = df1.dropna(subset=[c for c in cols_needed if c in df1.columns]).copy()\n",
    "\n",
    "# ============================================================\n",
    "# 2) Fix collinearity\n",
    "# ============================================================\n",
    "type_cols  = [c for c in X_vars if c.startswith(\"type_\")]\n",
    "model_cols = [c for c in X_vars if c.startswith(\"model_\")]\n",
    "\n",
    "def drop_one_present(cols, prefer):\n",
    "    for p in prefer:\n",
    "        if p in cols:\n",
    "            return p\n",
    "    return cols[0] if cols else None\n",
    "\n",
    "drop_type  = drop_one_present(type_cols,  [\"type_2 ROOM\"])\n",
    "drop_model = drop_one_present(model_cols, [\"model_Standard\"])\n",
    "to_drop = [c for c in [drop_type, drop_model] if c]\n",
    "X_vars = [c for c in X_vars if c not in to_drop]\n",
    "\n",
    "# Remove zero-variance\n",
    "zero_var = [c for c in X_vars if df1[c].std(ddof=0) == 0]\n",
    "if zero_var:\n",
    "    warnings.warn(f\"Dropping zero-variance vars: {zero_var}\")\n",
    "    X_vars = [c for c in X_vars if c not in zero_var]\n",
    "\n",
    "# Iterative VIF pruning\n",
    "def prune_by_vif(df, predictors, thresh=30.0, max_loops=10):\n",
    "    preds = predictors[:]\n",
    "    for _ in range(max_loops):\n",
    "        X = sm.add_constant(df[preds].values, has_constant='add')\n",
    "        vifs = [variance_inflation_factor(X, i+1) for i in range(len(preds))]\n",
    "        if np.nanmax(vifs) < thresh:\n",
    "            break\n",
    "        worst = preds[int(np.nanargmax(vifs))]\n",
    "        warnings.warn(f\"Dropping high-VIF var: {worst} (VIF≈{np.nanmax(vifs):.1f})\")\n",
    "        preds.remove(worst)\n",
    "    return preds\n",
    "\n",
    "X_vars = prune_by_vif(df1, X_vars, thresh=30.0)\n",
    "\n",
    "# ============================================================\n",
    "# 3) Build matrices and bandwidth\n",
    "# ============================================================\n",
    "coords = np.column_stack([df1.geometry.x.values, df1.geometry.y.values])\n",
    "y = df1[[Y]].values\n",
    "X = df1[X_vars].values\n",
    "n, k = X.shape\n",
    "p = k + 1\n",
    "\n",
    "bw_min_safe = max(p + 5, int(0.02 * n), 60)\n",
    "bw_max_safe = max(bw_min_safe + 40, int(0.25 * n))\n",
    "\n",
    "def pick_bw(coords, y, X, bw_min, bw_max, fixed=False, kernel='bisquare'):\n",
    "    sel = Sel_BW(coords, y, X, fixed=fixed, kernel=kernel)\n",
    "    try:\n",
    "        return sel.search(bw_min=bw_min, bw_max=bw_max)\n",
    "    except Exception:\n",
    "        warnings.warn(\"Bandwidth search failed; retry with fixed kernel & larger bw_min.\")\n",
    "        sel2 = Sel_BW(coords, y, X, fixed=True, kernel=kernel)\n",
    "        return sel2.search(bw_min=bw_min+40, bw_max=bw_max+200)\n",
    "\n",
    "bw = pick_bw(coords, y, X, bw_min_safe, bw_max_safe, fixed=False)\n",
    "print(f\"Selected bandwidth: {bw}\")\n",
    "\n",
    "# ============================================================\n",
    "# 4) Fit GWR safely\n",
    "# ============================================================\n",
    "def fit_gwr(coords, y, X, bw, fixed=False, kernel='bisquare'):\n",
    "    try:\n",
    "        mdl = GWR(coords, y, X, bw=bw, fixed=fixed, kernel=kernel, spherical=False)\n",
    "        return mdl.fit()\n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"GWR fit failed ({e}); retrying with larger bw.\")\n",
    "        bw2 = max(bw + 40, p + 40)\n",
    "        mdl2 = GWR(coords, y, X, bw=bw2, fixed=True, kernel=kernel, spherical=False)\n",
    "        return mdl2.fit()\n",
    "\n",
    "gwr_res = fit_gwr(coords, y, X, bw, fixed=False)\n",
    "print(f\"AICc: {gwr_res.aicc:.3f}, RSS: {gwr_res.resid_ss:.3f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 5) Collect local results (robust SE logic)\n",
    "# ============================================================\n",
    "param_names = [\"Intercept\"] + X_vars\n",
    "params = pd.DataFrame(gwr_res.params, columns=param_names)\n",
    "tvals  = pd.DataFrame(gwr_res.tvalues, columns=[f\"t_{c}\" for c in param_names])\n",
    "\n",
    "# robust SE handling\n",
    "if hasattr(gwr_res, \"se\"):\n",
    "    se_arr = gwr_res.se\n",
    "elif hasattr(gwr_res, \"bse\"):\n",
    "    se_arr = gwr_res.bse\n",
    "else:\n",
    "    t_only = tvals.copy()\n",
    "    t_only.columns = [c.replace(\"t_\", \"\") for c in t_only.columns]\n",
    "    tiny = 1e-12\n",
    "    t_only = t_only.where(t_only.abs() > tiny, np.nan)\n",
    "    se_arr = params.values / t_only.values\n",
    "\n",
    "se = pd.DataFrame(se_arr, columns=[f\"se_{c}\" for c in param_names])\n",
    "\n",
    "locals_df = pd.concat(\n",
    "    [df1[[\"subzone_name\"]].reset_index(drop=True), params, tvals, se],\n",
    "    axis=1\n",
    ")\n",
    "locals_df[\"local_R2\"] = gwr_res.localR2\n",
    "\n",
    "locals_gdf = gpd.GeoDataFrame(\n",
    "    pd.concat([locals_df, df1[[\"geometry\"]].reset_index(drop=True)], axis=1),\n",
    "    geometry=\"geometry\", crs=df1.crs\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 6) Subzone-level aggregation (same as before)\n",
    "# ============================================================\n",
    "subzone_geoms = {}\n",
    "has_poly = \"subzone_geom\" in df1.columns and df1[\"subzone_geom\"].notna().any()\n",
    "if has_poly:\n",
    "    poly = (\n",
    "        df1.loc[df1[\"subzone_geom\"].notna(), [\"subzone_name\", \"subzone_geom\"]]\n",
    "        .drop_duplicates(subset=[\"subzone_name\", \"subzone_geom\"])\n",
    "        .groupby(\"subzone_name\")[\"subzone_geom\"].apply(lambda s: s.unary_union)\n",
    "        .reset_index().rename(columns={\"subzone_geom\": \"geometry\"})\n",
    "    )\n",
    "    poly_gdf = gpd.GeoDataFrame(poly, geometry=\"geometry\", crs=df1.crs)\n",
    "    subzone_geoms = dict(zip(poly_gdf[\"subzone_name\"], poly_gdf[\"geometry\"]))\n",
    "\n",
    "for sz, g in df1.groupby(\"subzone_name\"):\n",
    "    if sz not in subzone_geoms or subzone_geoms[sz] is None:\n",
    "        pts = [geom for geom in g.geometry.values if geom is not None]\n",
    "        if len(pts) >= 3:\n",
    "            subzone_geoms[sz] = MultiPoint(pts).convex_hull\n",
    "        elif len(pts) > 0:\n",
    "            subzone_geoms[sz] = MultiPoint(pts).envelope\n",
    "\n",
    "agg_cols = param_names + [f\"t_{c}\" for c in param_names] + [f\"se_{c}\" for c in param_names] + [\"local_R2\"]\n",
    "agg_map = {c: \"mean\" for c in agg_cols}\n",
    "subzone_wide = locals_df.groupby(\"subzone_name\").agg(agg_map).reset_index()\n",
    "subzone_wide[\"geometry\"] = subzone_wide[\"subzone_name\"].map(subzone_geoms)\n",
    "gsubzone = gpd.GeoDataFrame(subzone_wide, geometry=\"geometry\", crs=df1.crs).dropna(subset=[\"geometry\"])\n",
    "\n",
    "# ============================================================\n",
    "# 7) Save outputs\n",
    "# ============================================================\n",
    "locals_gdf.to_parquet(\"processed_n/gwr_locals_points.parquet\", index=False)\n",
    "locals_gdf.to_file(\"processed_n/gwr_locals_points.gpkg\", driver=\"GPKG\")\n",
    "\n",
    "gsubzone.to_parquet(\"processed_n/gwr_subzone_coeffs_wide.parquet\", index=False)\n",
    "gsubzone.to_file(\"processed_n/gwr_subzone_coeffs_wide.gpkg\", driver=\"GPKG\")\n",
    "\n",
    "locals_df.to_csv(\"processed_n/gwr_locals_points_wide.csv\", index=False)\n",
    "subzone_wide.to_csv(\"processed_n/gwr_subzone_coeffs_wide.csv\", index=False)\n",
    "\n",
    "print(\"✅ GWR completed successfully and files saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bc5bd7-7e6a-4e97-b506-2dba45151f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc62f477-cdf4-4a37-b5c9-7742ea10b1ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52723a42-8e50-47b1-9987-cc442c100702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280c4501-578a-4c41-ba19-feb96e51315a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da2b674-ecb4-4e7f-ba41-01dc478eff78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3792534-28a5-4c92-b7ed-aec9c377b1cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f72b02-0612-495b-bfa6-49dcf3d3f425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e80a314e-0412-495e-9050-42020442120f",
   "metadata": {},
   "source": [
    "#### The following is trash code, just test, don't care."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac8d741-6a5e-4215-a823-be6d52f8b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Run OLS separately by town (local models)\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Assuming df is already loaded (from hdb_ols.parquet)\n",
    "# and you have a 'town' column\n",
    "# assert \"subzone_name\" in df.columns, \"Your dataset must contain a 'subzone_name' column.\"\n",
    "\n",
    "Y = \"log_price\"\n",
    "# X_vars = [\n",
    "#     \"dist_mrt\", \"dist_hcen\", \"dist_scen\", \"bus_count_400m\", \"resale_age\", \"storey_mid\",\n",
    "#     \"type_2 ROOM\", \"type_3 ROOM\", \"type_4 ROOM\", \"type_5 ROOM\", \"type_EXECUTIVE\", \"type_MULTI-GENERATION\",\n",
    "#     \"model_3Gen\", \"model_Adjoined flat\", \"model_Apartment\", \"model_DBSS\", \"model_Improved\",\n",
    "#     \"model_Improved-Maisonette\", \"model_Maisonette\", \"model_Model A\", \"model_Model A-Maisonette\",\n",
    "#     \"model_Model A2\", \"model_Multi Generation\", \"model_New Generation\", \"model_Premium Apartment\",\n",
    "#     \"model_Premium Apartment Loft\", \"model_Simplified\", \"model_Standard\", \"model_Terrace\",\n",
    "#     \"model_Type S1\", \"model_Type S2\"\n",
    "# ]\n",
    "X_vars = [\n",
    "    \"dist_mrt\", \"dist_hcen\", \"dist_scen\", \"bus_count_400m\", \"resale_age\", \"storey_mid\",\n",
    "    \"type_2 ROOM\", \"type_3 ROOM\", \"type_4 ROOM\", \"type_5 ROOM\", \"type_EXECUTIVE\", \"type_MULTI-GENERATION\",\n",
    "    \"model_3Gen\", \"model_Adjoined flat\", \"model_Apartment\", \"model_DBSS\", \"model_Improved\",\n",
    "    \"model_Improved-Maisonette\", \"model_Maisonette\", \"model_Model A\", \"model_Model A-Maisonette\",\n",
    "    \"model_Model A2\", \"model_Multi Generation\", \"model_New Generation\", \"model_Premium Apartment\",\n",
    "    \"model_Premium Apartment Loft\", \"model_Simplified\", \"model_Standard\", \"model_Terrace\",\n",
    "    \"model_Type S1\", \"model_Type S2\"\n",
    "]\n",
    "\n",
    "results_summary = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e858d3c7-fd7c-412a-b70e-d8956a66b288",
   "metadata": {},
   "outputs": [],
   "source": [
    "for town, df_sub in df_1.groupby(\"town\"):\n",
    "    df_sub = df_sub[[Y] + X_vars].dropna()\n",
    "    if len(df_sub) < len(X_vars) + 5:\n",
    "        print(f\"Skipping {town}: not enough observations ({len(df_sub)})\")\n",
    "        continue\n",
    "    \n",
    "    X = sm.add_constant(df_sub[X_vars])\n",
    "    y = df_sub[Y]\n",
    "    \n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    results_summary.append({\n",
    "        \"town\": town,\n",
    "        \"n_obs\": len(df_sub),\n",
    "        \"R2\": model.rsquared,\n",
    "        \"Adj_R2\": model.rsquared_adj,\n",
    "        \"AIC\": model.aic,\n",
    "        \"BIC\": model.bic,\n",
    "        \"F_pval\": model.f_pvalue\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results_summary).sort_values(\"R2\", ascending=False)\n",
    "results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d541e3a-dbb1-4490-81ca-f95aff0d602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Extract full coefficient table per town\n",
    "# ============================================================\n",
    "\n",
    "coeffs_list = []\n",
    "\n",
    "for town, df_sub in df_1.groupby(\"town\"):\n",
    "    df_sub = df_sub[[Y] + X_vars].dropna()\n",
    "    if len(df_sub) < len(X_vars) + 5:\n",
    "        continue\n",
    "\n",
    "    X = sm.add_constant(df_sub[X_vars])\n",
    "    y = df_sub[Y]\n",
    "    model = sm.OLS(y, X).fit()\n",
    "\n",
    "    # Convert coefficients to a dict row\n",
    "    row = {\"town\": town, \"n_obs\": len(df_sub)}\n",
    "    for param, val in model.params.items():\n",
    "        row[param] = val\n",
    "    coeffs_list.append(row)\n",
    "\n",
    "coeff_df = pd.DataFrame(coeffs_list).set_index(\"town\")\n",
    "coeff_df.to_csv(\"town_level_ols_coefficients_resaleprice.csv\")\n",
    "coeff_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa19c7d-57e9-4e47-94ee-78b8b1586f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for town, df_sub in df_1.groupby(\"town\"):\n",
    "    df_sub = df_sub[[Y] + X_vars].dropna()\n",
    "    if len(df_sub) < len(X_vars) + 5:\n",
    "        continue\n",
    "    # a += len(df_sub)\n",
    "    # print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df156d0c-d0d9-472d-8d47-6bd2a9f0a8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['resale_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b884cd7-50b9-4a19-a20e-d485eae3bdec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757687a2-4657-41fa-addb-08d64f7295f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb75a94-8474-4ea4-898c-49e33e17cd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
